{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l3WJh-90ZwxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc1599e-e458-47f8-ad9c-9d358f5d777d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip -q install rdkit-pypi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip -q install Pillow"
      ],
      "metadata": {
        "id": "fmIOOVdbuJBU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem.Draw import IPythonConsole, MolsToGridImage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "RDLogger.DisableLog(\"rdApp.*\")"
      ],
      "metadata": {
        "id": "PNTXcGrxrOR3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = tf.keras.utils.get_file(\n",
        "    \"qm9.csv\", \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\"\n",
        ")\n",
        "\n",
        "data = []\n",
        "with open(csv_path, \"r\") as f:\n",
        "    for line in f.readlines()[1:]:\n",
        "        data.append(line.split(\",\")[1])\n",
        "\n",
        "# Let's look at a molecule of the dataset\n",
        "smiles = data[1000]\n",
        "print(\"SMILES:\", smiles)\n",
        "molecule = Chem.MolFromSmiles(smiles)\n",
        "print(\"Num heavy atoms:\", molecule.GetNumHeavyAtoms())\n",
        "molecule"
      ],
      "metadata": {
        "id": "_pTLMYoAuWNK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "b9c0d8b3-3e46-422b-e526-8bf5d3a4b346"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\n",
            "29856825/29856825 [==============================] - 1s 0us/step\n",
            "SMILES: Cn1cncc1O\n",
            "Num heavy atoms: 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7f3d311a02e0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atom_mapping = {\n",
        "    \"C\": 0,\n",
        "    0: \"C\",\n",
        "    \"N\": 1,\n",
        "    1: \"N\",\n",
        "    \"O\": 2,\n",
        "    2: \"O\",\n",
        "    \"F\": 3,\n",
        "    3: \"F\",\n",
        "}\n",
        "\n",
        "bond_mapping = {\n",
        "    \"SINGLE\": 0,\n",
        "    0: Chem.BondType.SINGLE,\n",
        "    \"DOUBLE\": 1,\n",
        "    1: Chem.BondType.DOUBLE,\n",
        "    \"TRIPLE\": 2,\n",
        "    2: Chem.BondType.TRIPLE,\n",
        "    \"AROMATIC\": 3,\n",
        "    3: Chem.BondType.AROMATIC,\n",
        "}\n",
        "\n",
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space\n",
        "\n",
        "\n",
        "def smiles_to_graph(smiles):\n",
        "    # Converts SMILES to molecule object\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Initialize adjacency and feature tensor\n",
        "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
        "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
        "\n",
        "    # loop over each atom in molecule\n",
        "    for atom in molecule.GetAtoms():\n",
        "        i = atom.GetIdx()\n",
        "        atom_type = atom_mapping[atom.GetSymbol()]\n",
        "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
        "        # loop over one-hop neighbors\n",
        "        for neighbor in atom.GetNeighbors():\n",
        "            j = neighbor.GetIdx()\n",
        "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
        "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
        "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
        "\n",
        "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
        "    # Notice: channels-first\n",
        "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
        "\n",
        "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
        "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
        "\n",
        "    return adjacency, features\n",
        "\n",
        "\n",
        "def graph_to_molecule(graph):\n",
        "    # Unpack graph\n",
        "    adjacency, features = graph\n",
        "\n",
        "    # RWMol is a molecule object intended to be edited\n",
        "    molecule = Chem.RWMol()\n",
        "\n",
        "    # Remove \"no atoms\" & atoms with no bonds\n",
        "    keep_idx = np.where(\n",
        "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
        "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
        "    )[0]\n",
        "    features = features[keep_idx]\n",
        "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
        "\n",
        "    # Add atoms to molecule\n",
        "    for atom_type_idx in np.argmax(features, axis=1):\n",
        "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
        "        _ = molecule.AddAtom(atom)\n",
        "\n",
        "    # Add bonds between atoms in molecule; based on the upper triangles\n",
        "    # of the [symmetric] adjacency tensor\n",
        "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
        "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
        "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
        "            continue\n",
        "        bond_type = bond_mapping[bond_ij]\n",
        "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
        "\n",
        "    # Sanitize the molecule; for more information on sanitization, see\n",
        "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
        "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
        "    # Let's be strict. If sanitization fails, return None\n",
        "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
        "        return None\n",
        "\n",
        "    return molecule\n",
        "\n",
        "\n",
        "# Test helper functions\n",
        "graph_to_molecule(smiles_to_graph(smiles))"
      ],
      "metadata": {
        "id": "azwWkBj7udOL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "c8c0764e-6514-427e-f44d-3818430aa68a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.RWMol at 0x7f3d2ebe1530>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_tensor, feature_tensor = [], []\n",
        "for smiles in data[::10]:\n",
        "    adjacency, features = smiles_to_graph(smiles)\n",
        "    adjacency_tensor.append(adjacency)\n",
        "    feature_tensor.append(features)\n",
        "\n",
        "adjacency_tensor = np.array(adjacency_tensor)\n",
        "feature_tensor = np.array(feature_tensor)\n",
        "\n",
        "print(\"adjacency_tensor.shape =\", adjacency_tensor.shape)\n",
        "print(\"feature_tensor.shape =\", feature_tensor.shape)"
      ],
      "metadata": {
        "id": "BaNgU1IFur1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d819f4e8-834d-4452-da5b-9a88f9a65e00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjacency_tensor.shape = (13389, 5, 9, 9)\n",
            "feature_tensor.shape = (13389, 9, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GraphGenerator(\n",
        "    dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape,\n",
        "):\n",
        "    z = keras.layers.Input(shape=(LATENT_DIM,))\n",
        "    # Propagate through one or more densely connected layers\n",
        "    x = z\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"tanh\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Map outputs of previous layer (x) to [continuous] adjacency tensors (x_adjacency)\n",
        "    x_adjacency = keras.layers.Dense(tf.math.reduce_prod(adjacency_shape))(x)\n",
        "    x_adjacency = keras.layers.Reshape(adjacency_shape)(x_adjacency)\n",
        "    # Symmetrify tensors in the last two dimensions\n",
        "    x_adjacency = (x_adjacency + tf.transpose(x_adjacency, (0, 1, 3, 2))) / 2\n",
        "    x_adjacency = keras.layers.Softmax(axis=1)(x_adjacency)\n",
        "\n",
        "    # Map outputs of previous layer (x) to [continuous] feature tensors (x_features)\n",
        "    x_features = keras.layers.Dense(tf.math.reduce_prod(feature_shape))(x)\n",
        "    x_features = keras.layers.Reshape(feature_shape)(x_features)\n",
        "    x_features = keras.layers.Softmax(axis=2)(x_features)\n",
        "\n",
        "    return keras.Model(inputs=z, outputs=[x_adjacency, x_features], name=\"Generator\")\n",
        "\n",
        "\n",
        "generator = GraphGenerator(\n",
        "    dense_units=[128, 256, 512],\n",
        "    dropout_rate=0.2,\n",
        "    latent_dim=LATENT_DIM,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "TS3pEc00utFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab85eea-f3d6-46de-a4d1-b673f5c02f41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Generator\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  8320      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 256)                  33024     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 512)                  131584    ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 512)                  0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 405)                  207765    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 5, 9, 9)              0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose (TF  (None, 5, 9, 9)              0         ['reshape[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 5, 9, 9)              0         ['reshape[0][0]',             \n",
            " Lambda)                                                             'tf.compat.v1.transpose[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 45)                   23085     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambd  (None, 5, 9, 9)              0         ['tf.__operators__.add[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 9, 5)                 0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " softmax (Softmax)           (None, 5, 9, 9)              0         ['tf.math.truediv[0][0]']     \n",
            "                                                                                                  \n",
            " softmax_1 (Softmax)         (None, 9, 5)                 0         ['reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 403778 (1.54 MB)\n",
            "Trainable params: 403778 (1.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GraphGenerator(\n",
        "    dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape,\n",
        "):\n",
        "    z = keras.layers.Input(shape=(LATENT_DIM,))\n",
        "    # Propagate through one or more densely connected layers\n",
        "    x = z\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"tanh\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Map outputs of previous layer (x) to [continuous] adjacency tensors (x_adjacency)\n",
        "    x_adjacency = keras.layers.Dense(tf.math.reduce_prod(adjacency_shape))(x)\n",
        "    x_adjacency = keras.layers.Reshape(adjacency_shape)(x_adjacency)\n",
        "    # Symmetrify tensors in the last two dimensions\n",
        "    x_adjacency = (x_adjacency + tf.transpose(x_adjacency, (0, 1, 3, 2))) / 2\n",
        "    x_adjacency = keras.layers.Softmax(axis=1)(x_adjacency)\n",
        "\n",
        "    # Map outputs of previous layer (x) to [continuous] feature tensors (x_features)\n",
        "    x_features = keras.layers.Dense(tf.math.reduce_prod(feature_shape))(x)\n",
        "    x_features = keras.layers.Reshape(feature_shape)(x_features)\n",
        "    x_features = keras.layers.Softmax(axis=2)(x_features)\n",
        "\n",
        "    return keras.Model(inputs=z, outputs=[x_adjacency, x_features], name=\"Generator\")\n",
        "\n",
        "\n",
        "generator = GraphGenerator(\n",
        "    dense_units=[128, 256, 512],\n",
        "    dropout_rate=0.2,\n",
        "    latent_dim=LATENT_DIM,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "fC4ee09Xu3Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258c8d4d-ce46-48ae-959b-9eacc8aed693"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Generator\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 128)                  8320      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 128)                  0         ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256)                  33024     ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 256)                  0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 512)                  131584    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 512)                  0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 405)                  207765    ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 5, 9, 9)              0         ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_1 (  (None, 5, 9, 9)              0         ['reshape_2[0][0]']           \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None, 5, 9, 9)              0         ['reshape_2[0][0]',           \n",
            " OpLambda)                                                           'tf.compat.v1.transpose_1[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 45)                   23085     ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " tf.math.truediv_1 (TFOpLam  (None, 5, 9, 9)              0         ['tf.__operators__.add_1[0][0]\n",
            " bda)                                                               ']                            \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)         (None, 9, 5)                 0         ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " softmax_2 (Softmax)         (None, 5, 9, 9)              0         ['tf.math.truediv_1[0][0]']   \n",
            "                                                                                                  \n",
            " softmax_3 (Softmax)         (None, 9, 5)                 0         ['reshape_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 403778 (1.54 MB)\n",
            "Trainable params: 403778 (1.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RelationalGraphConvLayer(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        units=128,\n",
        "        activation=\"relu\",\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        bond_dim = input_shape[0][1]\n",
        "        atom_dim = input_shape[1][2]\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(bond_dim, atom_dim, self.units),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            trainable=True,\n",
        "            name=\"W\",\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(bond_dim, 1, self.units),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                trainable=True,\n",
        "                name=\"b\",\n",
        "                dtype=tf.float32,\n",
        "            )\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        adjacency, features = inputs\n",
        "        # Aggregate information from neighbors\n",
        "        x = tf.matmul(adjacency, features[:, None, :, :])\n",
        "        # Apply linear transformation\n",
        "        x = tf.matmul(x, self.kernel)\n",
        "        if self.use_bias:\n",
        "            x += self.bias\n",
        "        # Reduce bond types dim\n",
        "        x_reduced = tf.reduce_sum(x, axis=1)\n",
        "        # Apply non-linear transformation\n",
        "        return self.activation(x_reduced)\n",
        "\n",
        "\n",
        "def GraphDiscriminator(\n",
        "    gconv_units, dense_units, dropout_rate, adjacency_shape, feature_shape\n",
        "):\n",
        "\n",
        "    adjacency = keras.layers.Input(shape=adjacency_shape)\n",
        "    features = keras.layers.Input(shape=feature_shape)\n",
        "\n",
        "    # Propagate through one or more graph convolutional layers\n",
        "    features_transformed = features\n",
        "    for units in gconv_units:\n",
        "        features_transformed = RelationalGraphConvLayer(units)(\n",
        "            [adjacency, features_transformed]\n",
        "        )\n",
        "\n",
        "    # Reduce 2-D representation of molecule to 1-D\n",
        "    x = keras.layers.GlobalAveragePooling1D()(features_transformed)\n",
        "\n",
        "    # Propagate through one or more densely connected layers\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # For each molecule, output a single scalar value expressing the\n",
        "    # \"realness\" of the inputted molecule\n",
        "    x_out = keras.layers.Dense(1, dtype=\"float32\")(x)\n",
        "\n",
        "    return keras.Model(inputs=[adjacency, features], outputs=x_out)\n",
        "\n",
        "\n",
        "discriminator = GraphDiscriminator(\n",
        "    gconv_units=[128, 128, 128, 128],\n",
        "    dense_units=[512, 512],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "bZ17RFeKv_hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6462e04-d530-4478-dca8-ad4fb568ec0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 5, 9, 9)]            0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 9, 5)]               0         []                            \n",
            "                                                                                                  \n",
            " relational_graph_conv_laye  (None, 9, 128)               3200      ['input_3[0][0]',             \n",
            " r (RelationalGraphConvLaye                                          'input_4[0][0]']             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " relational_graph_conv_laye  (None, 9, 128)               81920     ['input_3[0][0]',             \n",
            " r_1 (RelationalGraphConvLa                                          'relational_graph_conv_layer[\n",
            " yer)                                                               0][0]']                       \n",
            "                                                                                                  \n",
            " relational_graph_conv_laye  (None, 9, 128)               81920     ['input_3[0][0]',             \n",
            " r_2 (RelationalGraphConvLa                                          'relational_graph_conv_layer_\n",
            " yer)                                                               1[0][0]']                     \n",
            "                                                                                                  \n",
            " relational_graph_conv_laye  (None, 9, 128)               81920     ['input_3[0][0]',             \n",
            " r_3 (RelationalGraphConvLa                                          'relational_graph_conv_layer_\n",
            " yer)                                                               2[0][0]']                     \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 128)                  0         ['relational_graph_conv_layer_\n",
            " GlobalAveragePooling1D)                                            3[0][0]']                     \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 512)                  66048     ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 512)                  0         ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 512)                  262656    ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 512)                  0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 1)                    513       ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 578177 (2.21 MB)\n",
            "Trainable params: 578177 (2.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphWGAN(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        discriminator_steps=1,\n",
        "        generator_steps=1,\n",
        "        gp_weight=10,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.discriminator_steps = discriminator_steps\n",
        "        self.generator_steps = generator_steps\n",
        "        self.gp_weight = gp_weight\n",
        "        self.latent_dim = self.generator.input_shape[-1]\n",
        "\n",
        "    def compile(self, optimizer_generator, optimizer_discriminator, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.optimizer_generator = optimizer_generator\n",
        "        self.optimizer_discriminator = optimizer_discriminator\n",
        "        self.metric_generator = keras.metrics.Mean(name=\"loss_gen\")\n",
        "        self.metric_discriminator = keras.metrics.Mean(name=\"loss_dis\")\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "\n",
        "        if isinstance(inputs[0], tuple):\n",
        "            inputs = inputs[0]\n",
        "\n",
        "        graph_real = inputs\n",
        "\n",
        "        self.batch_size = tf.shape(inputs[0])[0]\n",
        "\n",
        "        # Train the discriminator for one or more steps\n",
        "        for _ in range(self.discriminator_steps):\n",
        "            z = tf.random.normal((self.batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                graph_generated = self.generator(z, training=True)\n",
        "                loss = self._loss_discriminator(graph_real, graph_generated)\n",
        "\n",
        "            grads = tape.gradient(loss, self.discriminator.trainable_weights)\n",
        "            self.optimizer_discriminator.apply_gradients(\n",
        "                zip(grads, self.discriminator.trainable_weights)\n",
        "            )\n",
        "            self.metric_discriminator.update_state(loss)\n",
        "\n",
        "        # Train the generator for one or more steps\n",
        "        for _ in range(self.generator_steps):\n",
        "            z = tf.random.normal((self.batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                graph_generated = self.generator(z, training=True)\n",
        "                loss = self._loss_generator(graph_generated)\n",
        "\n",
        "                grads = tape.gradient(loss, self.generator.trainable_weights)\n",
        "                self.optimizer_generator.apply_gradients(\n",
        "                    zip(grads, self.generator.trainable_weights)\n",
        "                )\n",
        "                self.metric_generator.update_state(loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def _loss_discriminator(self, graph_real, graph_generated):\n",
        "        logits_real = self.discriminator(graph_real, training=True)\n",
        "        logits_generated = self.discriminator(graph_generated, training=True)\n",
        "        loss = tf.reduce_mean(logits_generated) - tf.reduce_mean(logits_real)\n",
        "        loss_gp = self._gradient_penalty(graph_real, graph_generated)\n",
        "        return loss + loss_gp * self.gp_weight\n",
        "\n",
        "    def _loss_generator(self, graph_generated):\n",
        "        logits_generated = self.discriminator(graph_generated, training=True)\n",
        "        return -tf.reduce_mean(logits_generated)\n",
        "\n",
        "    def _gradient_penalty(self, graph_real, graph_generated):\n",
        "        # Unpack graphs\n",
        "        adjacency_real, features_real = graph_real\n",
        "        adjacency_generated, features_generated = graph_generated\n",
        "\n",
        "        # Generate interpolated graphs (adjacency_interp and features_interp)\n",
        "        alpha = tf.random.uniform([self.batch_size])\n",
        "        alpha = tf.reshape(alpha, (self.batch_size, 1, 1, 1))\n",
        "        adjacency_interp = (adjacency_real * alpha) + (1 - alpha) * adjacency_generated\n",
        "        alpha = tf.reshape(alpha, (self.batch_size, 1, 1))\n",
        "        features_interp = (features_real * alpha) + (1 - alpha) * features_generated\n",
        "\n",
        "        # Compute the logits of interpolated graphs\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(adjacency_interp)\n",
        "            tape.watch(features_interp)\n",
        "            logits = self.discriminator(\n",
        "                [adjacency_interp, features_interp], training=True\n",
        "            )\n",
        "\n",
        "        # Compute the gradients with respect to the interpolated graphs\n",
        "        grads = tape.gradient(logits, [adjacency_interp, features_interp])\n",
        "        # Compute the gradient penalty\n",
        "        grads_adjacency_penalty = (1 - tf.norm(grads[0], axis=1)) ** 2\n",
        "        grads_features_penalty = (1 - tf.norm(grads[1], axis=2)) ** 2\n",
        "        return tf.reduce_mean(\n",
        "            tf.reduce_mean(grads_adjacency_penalty, axis=(-2, -1))\n",
        "            + tf.reduce_mean(grads_features_penalty, axis=(-1))\n",
        "        )"
      ],
      "metadata": {
        "id": "Smp5G825u_LK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wgan = GraphWGAN(generator, discriminator, discriminator_steps=1)\n",
        "\n",
        "wgan.compile(\n",
        "    optimizer_generator=keras.optimizers.Adadelta(5e-4),\n",
        "    optimizer_discriminator=keras.optimizers.Nadam(5e-4),\n",
        ")\n",
        "\n",
        "wgan.fit([adjacency_tensor, feature_tensor], epochs=10, batch_size=16)"
      ],
      "metadata": {
        "id": "rYeoJBp1rTpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c7047f-9ee6-4e87-b689-5312f4391865"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "837/837 [==============================] - 96s 97ms/step - loss_gen: 25.8856 - loss_dis: -32.6104\n",
            "Epoch 2/10\n",
            "837/837 [==============================] - 81s 97ms/step - loss_gen: 36.7847 - loss_dis: -32.9962\n",
            "Epoch 3/10\n",
            "837/837 [==============================] - 79s 94ms/step - loss_gen: 33.4613 - loss_dis: -33.3045\n",
            "Epoch 4/10\n",
            "837/837 [==============================] - 80s 95ms/step - loss_gen: 34.6366 - loss_dis: -34.1256\n",
            "Epoch 5/10\n",
            "837/837 [==============================] - 81s 96ms/step - loss_gen: 32.9912 - loss_dis: -34.2807\n",
            "Epoch 6/10\n",
            "837/837 [==============================] - 78s 93ms/step - loss_gen: 34.1732 - loss_dis: -33.7150\n",
            "Epoch 7/10\n",
            "837/837 [==============================] - 82s 98ms/step - loss_gen: 35.3262 - loss_dis: -33.2589\n",
            "Epoch 8/10\n",
            "837/837 [==============================] - 78s 93ms/step - loss_gen: 30.4953 - loss_dis: -33.1307\n",
            "Epoch 9/10\n",
            "837/837 [==============================] - 82s 99ms/step - loss_gen: 29.0033 - loss_dis: -33.9567\n",
            "Epoch 10/10\n",
            "837/837 [==============================] - 77s 92ms/step - loss_gen: 26.2486 - loss_dis: -33.1993\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f3d2e39aaa0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(generator, batch_size):\n",
        "    z = tf.random.normal((batch_size, LATENT_DIM))\n",
        "    graph = generator.predict(z)\n",
        "    # obtain one-hot encoded adjacency tensor\n",
        "    adjacency = tf.argmax(graph[0], axis=1)\n",
        "    adjacency = tf.one_hot(adjacency, depth=BOND_DIM, axis=1)\n",
        "    # Remove potential self-loops from adjacency\n",
        "    adjacency = tf.linalg.set_diag(adjacency, tf.zeros(tf.shape(adjacency)[:-1]))\n",
        "    # obtain one-hot encoded feature tensor\n",
        "    features = tf.argmax(graph[1], axis=2)\n",
        "    features = tf.one_hot(features, depth=ATOM_DIM, axis=2)\n",
        "    return [\n",
        "        graph_to_molecule([adjacency[i].numpy(), features[i].numpy()])\n",
        "        for i in range(batch_size)\n",
        "    ]\n",
        "\n",
        "\n",
        "molecules = sample(wgan.generator, batch_size=48)\n",
        "\n",
        "MolsToGridImage(\n",
        "    [m for m in molecules if m is not None][:25], molsPerRow=5, subImgSize=(150, 150)\n",
        ")"
      ],
      "metadata": {
        "id": "s6dEFzC2rzo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "4c6b8f20-0cb6-435f-c296-bf7bb918cae2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}